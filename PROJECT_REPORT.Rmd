---
title: "Predicting 30-Day Hospital Readmissions: A Comparative Analysis Using Logistic Regression and CART"
author: "Masheia Dzimba and Peter Mangoro"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
    fig_caption: true
    latex_engine: xelatex
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
    fig_caption: true
    theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                      fig.width = 10, fig.height = 6, fig.align = "center")
library(ggplot2)
library(dplyr)
library(knitr)
```

# Abstract

This study aims to predict 30-day hospital readmissions for patients with diabetes using patient demographic, diagnostic, and treatment-related features. We employed two statistical modeling approaches: Logistic Regression and Classification and Regression Trees (CART). The dataset consists of 24,996 patient encounters from 130 US hospitals collected between 1999-2008. Our analysis identified previous inpatient visits, age groups, and medical specialty as key predictors of readmission. The Logistic Regression model achieved an accuracy of 61.84% and AUC of 0.648, while CART achieved 60.78% accuracy and AUC of 0.605. Both models demonstrate moderate predictive performance, suggesting that additional clinical variables may be needed to improve predictions. The Logistic Regression model provides more detailed statistical insights with odds ratios and significance testing, making it preferable for clinical decision support. This analysis highlights the importance of patient history and demographics in predicting readmission risk, with implications for healthcare resource allocation and patient care planning.

# Introduction

## Background

Hospital readmissions within 30 days of discharge are a significant concern in healthcare, associated with increased costs, patient morbidity, and healthcare system burden. For patients with diabetes, readmission rates are particularly high, making early identification of at-risk patients crucial for improving outcomes and reducing healthcare costs.

## Research Question

**Can patient demographic, diagnostic, and treatment-related features effectively predict the likelihood of a patient being readmitted to the hospital within 30 days of discharge?**

## Objectives

1. Identify key predictors of 30-day hospital readmissions
2. Compare the performance of Logistic Regression and CART models
3. Evaluate model interpretability and clinical utility
4. Provide recommendations for clinical application

# Data Description

## Data Source

The dataset was obtained from Kaggle: "Diabetes 130-US Hospitals for 10 years" and contains 25,000 patient encounters from 130 US hospitals and integrated delivery networks over a 10-year period (1999-2008). The data was collected retrospectively from electronic health records (EHR) and anonymized for research purposes.

## Data Collection Method

This is an **observational study** - data was collected by observing patient outcomes and characteristics without any intervention or manipulation of variables by the researchers.

## Dependent Variable

**`readmitted`**: Binary categorical variable indicating whether the patient was readmitted to the hospital within 30 days of discharge.

- **Type**: Binary (after cleaning: 0 = Not Readmitted, 1 = Readmitted)
- **Distribution**: 47.02% readmitted, 52.98% not readmitted
- **Final sample size**: 24,996 observations (4 rows dropped due to missing primary diagnosis)

## Independent Variables

The analysis includes the following variables:

### Categorical Variables:
- **`age`**: Age groups ([40-50), [50-60), [60-70), [70-80), [80-90), [90-100))
- **`medical_specialty`**: Medical specialty (7 categories including "Missing")
- **`diag_1`**: Primary diagnosis (8 categories: Circulatory, Diabetes, Digestive, Injury, Musculoskeletal, Other, Respiratory)
- **`change`**: Change in medication (yes/no)
- **`diabetes_med`**: Diabetes medication prescribed (yes/no)

### Numerical Variables:
- **`time_in_hospital`**: Length of stay in days (Mean: 4.45, Range: 1-14)
- **`n_lab_procedures`**: Number of lab tests performed (Mean: 43.24)
- **`n_procedures`**: Number of procedures (Mean: 1.35, Range: 0-6)
- **`n_medications`**: Number of medications (Mean: 16.25, Range: 1-79)

# Methods

## Statistical Methods

This project employs a **comparative analysis** using two distinct statistical methods:

### 1. Logistic Regression (Primary Method)
- **Justification**: Standard method for modeling binary categorical response variables
- **Advantages**: Provides interpretable results (odds ratios), statistical significance testing, confidence intervals
- **Assumptions**: Linear relationships between predictors and log-odds of outcome

### 2. Classification and Regression Trees (CART) (Secondary Method)
- **Justification**: Non-parametric method that captures complex, non-linear relationships
- **Advantages**: Highly interpretable decision rules, no distributional assumptions
- **Comparison**: Evaluated against Logistic Regression based on predictive performance and interpretability

## Data Preprocessing

1. **Response Variable**: Converted to binary format (0/1)
2. **Missing Values**: 
   - Dropped 4 rows with missing primary diagnosis (0.02%)
   - Kept "Missing" as valid category for other variables
3. **Feature Engineering**: Created derived features (n_diagnoses, medications_per_day, total_previous_visits)
4. **Encoding**: 
   - Logistic Regression: Dummy/one-hot encoding
   - CART: Factor encoding

## Model Evaluation

Models were evaluated using:
- **Train/Test Split**: 70% training, 30% testing
- **Metrics**: Accuracy, Precision, Recall, Specificity, F1-Score, AUC-ROC
- **Statistical Tests**: Hypothesis testing for Logistic Regression coefficients

# Results

## Summary Statistics

```{r summary-stats, echo=FALSE, results='asis'}
comparison_table <- read.csv("plots/03_comparison_by_readmission.csv")
kable(comparison_table, caption = "Summary Statistics by Readmission Status")
```

## Data Visualizations

### Distribution of Readmission Status

```{r readmission-dist, echo=FALSE, fig.cap="Distribution of Readmitted Patients"}
knitr::include_graphics("plots/01_readmitted_distribution_ggplot.png")
```

### Numerical Variables by Readmission Status

```{r boxplots, echo=FALSE, fig.cap="Distribution of Numerical Variables by Readmission Status"}
knitr::include_graphics("plots/03_boxplots_combined.png")
```

### Categorical Variables Analysis

```{r categorical-viz, echo=FALSE, fig.cap="Readmission Rates by Primary Diagnosis"}
knitr::include_graphics("plots/03_readmission_rate_diag_1.png")
```

## Logistic Regression Results

### Model Performance

```{r logistic-metrics, echo=FALSE, results='asis'}
metrics_lr <- read.csv("plots/04_performance_metrics.csv")
kable(metrics_lr, caption = "Logistic Regression Performance Metrics")
```

### Regression Output

```{r regression-output, echo=FALSE, results='asis'}
reg_output <- read.csv("plots/04_regression_output.csv")
# Show top 10 significant variables
sig_vars <- reg_output[reg_output$P_Value < 0.05 & !is.na(reg_output$P_Value), ]
sig_vars <- sig_vars[order(sig_vars$P_Value), ][1:10, ]
kable(sig_vars[, c("Variable", "Coefficient", "P_Value", "Odds_Ratio", "CI_Lower", "CI_Upper")], 
      caption = "Top 10 Significant Variables in Logistic Regression Model")
```

### Hypothesis Testing

For each significant variable in the Logistic Regression model:

- **$H_0$**: $\beta_{variable} = 0$ (variable has no effect on readmission)
- **$H_1$**: $\beta_{variable} \neq 0$ (variable affects readmission)

All variables shown in the table above have p < 0.05, indicating we reject $H_0$ and conclude these variables are significant predictors.

### R-squared Interpretation

```{r rsquared, echo=FALSE, results='asis'}
r2_table <- read.csv("plots/04_rsquared.csv")
kable(r2_table, caption = "Pseudo R-squared Values")
```

The Logistic Regression model explains approximately **5.05%** of the variance in readmission status (McFadden's Pseudo $R^2$ = 0.0505). While this is relatively low, it is common for logistic regression models, and values above 0.2-0.4 are considered good.

### ROC Curve

```{r roc-logistic, echo=FALSE, fig.cap="ROC Curve: Logistic Regression Model (AUC = 0.648)"}
knitr::include_graphics("plots/04_roc_curve_ggplot.png")
```

## CART Results

### Model Performance

```{r cart-metrics, echo=FALSE, results='asis'}
metrics_cart <- read.csv("plots/05_performance_metrics.csv")
kable(metrics_cart, caption = "CART Model Performance Metrics")
```

### Decision Tree Visualization

```{r cart-tree, echo=FALSE, fig.cap="CART Decision Tree: Simple tree with one split based on total previous visits"}
knitr::include_graphics("plots/05_cart_tree_basic.png")
```

### Variable Importance

```{r cart-importance, echo=FALSE, results='asis'}
var_imp <- read.csv("plots/05_variable_importance.csv")
kable(head(var_imp, 10), caption = "Top 10 Most Important Variables in CART Model")
```

### ROC Curve

```{r roc-cart, echo=FALSE, fig.cap="ROC Curve: CART Model (AUC = 0.605)"}
knitr::include_graphics("plots/05_roc_curve_ggplot.png")
```

## Model Comparison

### Performance Comparison

```{r model-comparison, echo=FALSE, results='asis'}
comp_table <- read.csv("plots/06_model_comparison.csv")
kable(comp_table, caption = "Side-by-Side Performance Comparison")
```

### Visualization

```{r comparison-viz, echo=FALSE, fig.cap="Model Performance Comparison"}
knitr::include_graphics("plots/06_metrics_comparison.png")
```

```{r auc-comparison, echo=FALSE, fig.cap="AUC Comparison: Logistic Regression vs. CART"}
knitr::include_graphics("plots/06_auc_comparison.png")
```

### Model Selection

```{r justification, echo=FALSE, results='asis'}
justification <- read.csv("plots/06_model_justification.csv")
kable(justification, caption = "Model Comparison: Detailed Justification")
```

**Recommended Model: Logistic Regression**

**Reason**: Higher AUC (0.648 vs 0.605) and accuracy (61.84% vs 60.78%), with more detailed statistical insights including odds ratios, p-values, and confidence intervals.

# Discussion

## Key Findings

1. **Previous visits are the strongest predictor**: Both models identify previous hospital visits (inpatient, outpatient, emergency) as the most important factor in predicting readmission.

2. **Age and medical specialty matter**: Older patients (70-80, 80-90 age groups) and certain medical specialties (Cardiology) show higher readmission rates.

3. **Moderate model performance**: Both models achieve ~61% accuracy with AUC values below 0.7, suggesting room for improvement.

4. **Trade-offs between models**: 
   - Logistic Regression provides better performance and statistical rigor
   - CART offers superior simplicity and interpretability

## Clinical Implications

The identification of previous visits as a key predictor suggests that patients with complex medical histories require enhanced discharge planning and follow-up care. The moderate performance of both models indicates that additional clinical variables (e.g., lab results, vital signs, social determinants) may be needed for more accurate predictions.

# Conclusion

## Answer to Research Question

**Yes, patient demographic, diagnostic, and treatment-related features can predict the likelihood of 30-day hospital readmission, though with moderate accuracy (~61%).** The Logistic Regression model performs slightly better (AUC = 0.648) and provides more detailed statistical insights, making it preferable for clinical decision support.

## Why This Analysis is Important

1. **Healthcare Cost Reduction**: Early identification of high-risk patients can enable targeted interventions to prevent readmissions
2. **Patient Outcomes**: Improved discharge planning based on risk prediction can enhance patient care
3. **Resource Allocation**: Hospitals can allocate resources more efficiently by focusing on high-risk patients
4. **Clinical Decision Support**: Models provide evidence-based tools for healthcare providers

## Limitations

1. **Moderate Predictive Performance**: Both models show AUC < 0.7, indicating fair to poor discrimination
2. **Missing Variables**: Important clinical variables (lab results, vital signs, comorbidities) may be missing
3. **Data Age**: Data from 1999-2008 may not reflect current healthcare practices
4. **Missing Data**: High percentage of missing medical specialty (49.53%) may affect results
5. **Model Assumptions**: Logistic Regression assumes linear relationships; CART may be underfitting
6. **Generalizability**: Results may not generalize to other hospital systems or time periods

## Recommendations

1. **Feature Enhancement**: Include additional clinical variables (lab results, vital signs, social determinants)
2. **Advanced Methods**: Consider ensemble methods (Random Forest, Gradient Boosting) for improved performance
3. **Data Collection**: Collect more recent data to reflect current healthcare practices
4. **Clinical Application**: 
   - Use Logistic Regression for detailed risk assessment with statistical rigor
   - Use CART for simple screening tools requiring high interpretability
5. **Validation**: Validate models on external datasets before clinical deployment

# References

Kaggle. "Diabetes 130-US Hospitals for 10 years." Accessed November 14, 2025. https://www.kaggle.com/datasets/brandao/diabetes

---


